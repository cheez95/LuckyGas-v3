"""
Import customer data from Excel file to PostgreSQL database with comprehensive NaN handling
"""
import asyncio
import pandas as pd
import numpy as np
import sys
from pathlib import Path
from datetime import datetime
from typing import Any, Optional, Dict, List
from sqlalchemy.ext.asyncio import AsyncSession
import json

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent.parent / "backend"))

from app.core.database import async_session_maker, create_db_and_tables
from app.models.customer import Customer
from app.models.user import User, UserRole
from app.core.security import get_password_hash
from app.core.config import settings


class DataImportReport:
    """Track import statistics and data quality issues"""
    
    def __init__(self):
        self.total_rows = 0
        self.successful_imports = 0
        self.failed_imports = 0
        self.skipped_existing = 0
        self.nan_replacements: Dict[str, int] = {}
        self.errors: List[Dict[str, Any]] = []
        self.warnings: List[Dict[str, Any]] = []
        
    def add_nan_replacement(self, field: str):
        """Track when NaN values are replaced with defaults"""
        self.nan_replacements[field] = self.nan_replacements.get(field, 0) + 1
        
    def add_error(self, row_index: int, customer_code: str, error: str):
        """Record import errors"""
        self.errors.append({
            'row': row_index,
            'customer_code': customer_code,
            'error': str(error),
            'timestamp': datetime.now().isoformat()
        })
        
    def add_warning(self, row_index: int, customer_code: str, warning: str):
        """Record data quality warnings"""
        self.warnings.append({
            'row': row_index,
            'customer_code': customer_code,
            'warning': warning,
            'timestamp': datetime.now().isoformat()
        })
        
    def generate_report(self) -> Dict[str, Any]:
        """Generate comprehensive import report"""
        return {
            'summary': {
                'total_rows': self.total_rows,
                'successful_imports': self.successful_imports,
                'failed_imports': self.failed_imports,
                'skipped_existing': self.skipped_existing,
                'success_rate': f"{(self.successful_imports / self.total_rows * 100):.1f}%" if self.total_rows > 0 else "0%"
            },
            'data_quality': {
                'total_nan_replacements': sum(self.nan_replacements.values()),
                'nan_replacements_by_field': self.nan_replacements,
                'fields_with_most_nan': sorted(self.nan_replacements.items(), key=lambda x: x[1], reverse=True)[:10]
            },
            'errors': {
                'total': len(self.errors),
                'details': self.errors[:20]  # First 20 errors
            },
            'warnings': {
                'total': len(self.warnings),
                'details': self.warnings[:20]  # First 20 warnings
            },
            'timestamp': datetime.now().isoformat()
        }


def safe_int(value: Any, default: int = 0, field_name: str = None, report: DataImportReport = None) -> int:
    """Safely convert value to integer with NaN handling"""
    if pd.isna(value):
        if report and field_name:
            report.add_nan_replacement(field_name)
        return default
    try:
        # Handle float to int conversion
        if isinstance(value, float):
            return int(value)
        return int(value)
    except (ValueError, TypeError):
        if report and field_name:
            report.add_nan_replacement(field_name)
        return default


def safe_float(value: Any, default: float = 0.0, field_name: str = None, report: DataImportReport = None) -> float:
    """Safely convert value to float with NaN handling"""
    if pd.isna(value):
        if report and field_name:
            report.add_nan_replacement(field_name)
        return default
    try:
        return float(value)
    except (ValueError, TypeError):
        if report and field_name:
            report.add_nan_replacement(field_name)
        return default


def safe_str(value: Any, default: str = '', field_name: str = None, report: DataImportReport = None) -> str:
    """Safely convert value to string with NaN handling"""
    if pd.isna(value):
        if report and field_name:
            report.add_nan_replacement(field_name)
        return default
    return str(value).strip()


def safe_bool(value: Any, default: bool = False, field_name: str = None, report: DataImportReport = None) -> bool:
    """Safely convert value to boolean with NaN handling"""
    if pd.isna(value):
        if report and field_name:
            report.add_nan_replacement(field_name)
        return default
    # Handle various boolean representations
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    if isinstance(value, str):
        return value.lower() in ('true', 'yes', '1', 't', 'y')
    return default


async def create_superuser(session: AsyncSession):
    """Create the first superuser if it doesn't exist"""
    from sqlalchemy import select
    
    result = await session.execute(
        select(User).where(User.email == settings.FIRST_SUPERUSER)
    )
    if not result.scalar_one_or_none():
        superuser = User(
            email=settings.FIRST_SUPERUSER,
            username=settings.FIRST_SUPERUSER.split('@')[0],
            full_name="System Administrator",
            hashed_password=get_password_hash(settings.FIRST_SUPERUSER_PASSWORD),
            role=UserRole.SUPER_ADMIN,
            is_active=True
        )
        session.add(superuser)
        await session.commit()
        print(f"Created superuser: {settings.FIRST_SUPERUSER}")


async def import_customers():
    """Import customers from Excel file with comprehensive NaN handling"""
    # Initialize report
    report = DataImportReport()
    
    # Read Excel file
    excel_path = Path(__file__).parent.parent.parent / "raw" / "2025-05 client liss.xlsx"
    print(f"Reading Excel file: {excel_path}")
    
    try:
        df = pd.read_excel(excel_path)
        report.total_rows = len(df)
        print(f"Found {len(df)} customers in Excel file")
    except Exception as e:
        print(f"âŒ Error reading Excel file: {e}")
        return
    
    # Create database tables
    await create_db_and_tables()
    
    async with async_session_maker() as session:
        # Create superuser first
        await create_superuser(session)
        
        # Import customers
        for idx, row in df.iterrows():
            try:
                customer_code = safe_str(row.get('å®¢æˆ¶', ''), field_name='å®¢æˆ¶', report=report)
                
                if not customer_code:
                    report.add_warning(idx, 'Unknown', 'Missing customer code')
                    continue
                
                # Check if customer already exists
                from sqlalchemy import select
                result = await session.execute(
                    select(Customer).where(Customer.customer_code == customer_code)
                )
                if result.scalar_one_or_none():
                    report.skipped_existing += 1
                    continue
                
                # Create customer with comprehensive NaN handling
                customer = Customer(
                    customer_code=customer_code,
                    invoice_title=safe_str(row.get('é›»å­ç™¼ç¥¨æŠ¬é ­', ''), field_name='é›»å­ç™¼ç¥¨æŠ¬é ­', report=report),
                    short_name=safe_str(row.get('å®¢æˆ¶ç°¡ç¨±', ''), field_name='å®¢æˆ¶ç°¡ç¨±', report=report),
                    address=safe_str(row.get('åœ°å€', ''), field_name='åœ°å€', report=report),
                    
                    # Cylinder quantities - default to 0 (customer doesn't use this type)
                    cylinders_50kg=safe_int(row.get('50KG'), default=0, field_name='50KG', report=report),
                    cylinders_20kg=safe_int(row.get('20KG'), default=0, field_name='20KG', report=report),
                    cylinders_16kg=safe_int(row.get('16KG'), default=0, field_name='16KG', report=report),
                    cylinders_10kg=safe_int(row.get('10KG'), default=0, field_name='10KG', report=report),
                    cylinders_4kg=safe_int(row.get('4KG'), default=0, field_name='4KG', report=report),
                    
                    # Special cylinders - default to 0
                    cylinders_ying20=safe_int(row.get('ç‡Ÿ20'), default=0, field_name='ç‡Ÿ20', report=report),
                    cylinders_ying16=safe_int(row.get('ç‡Ÿ16'), default=0, field_name='ç‡Ÿ16', report=report),
                    cylinders_haoyun20=safe_int(row.get('å¥½é‹20'), default=0, field_name='å¥½é‹20', report=report),
                    cylinders_haoyun16=safe_int(row.get('å¥½é‹16'), default=0, field_name='å¥½é‹16', report=report),
                    
                    # Delivery preferences
                    area=safe_str(row.get('å€åŸŸ', ''), field_name='å€åŸŸ', report=report),
                    delivery_type=safe_int(row.get('1æ±½è»Š/2æ©Ÿè»Š/0å…¨éƒ¨'), default=0, field_name='1æ±½è»Š/2æ©Ÿè»Š/0å…¨éƒ¨', report=report),
                    
                    # Consumption data - sensible defaults
                    avg_daily_usage=safe_float(row.get('å¹³å‡æ—¥ä½¿ç”¨'), default=0.0, field_name='å¹³å‡æ—¥ä½¿ç”¨', report=report),
                    max_cycle_days=safe_int(row.get('æœ€å¤§é€±æœŸ'), default=30, field_name='æœ€å¤§é€±æœŸ', report=report),  # Default 30 days
                    can_delay_days=safe_int(row.get('å¯å»¶å¾Œå¤©æ•¸'), default=7, field_name='å¯å»¶å¾Œå¤©æ•¸', report=report),  # Default 7 days
                    monthly_delivery_volume=safe_float(row.get('æœˆé…é€é‡'), default=0.0, field_name='æœˆé…é€é‡', report=report),
                    
                    # Pricing
                    pricing_method=safe_str(row.get('è¨ˆåƒ¹æ–¹å¼', ''), field_name='è¨ˆåƒ¹æ–¹å¼', report=report),
                    payment_method=safe_str(row.get('çµå¸³æ–¹å¼', ''), field_name='çµå¸³æ–¹å¼', report=report),
                    
                    # Status flags - default to False
                    is_subscription=safe_bool(row.get('è¨‚é–±å¼æœƒå“¡'), default=False, field_name='è¨‚é–±å¼æœƒå“¡', report=report),
                    needs_report=safe_bool(row.get('ç™¼å ±'), default=False, field_name='ç™¼å ±', report=report),
                    needs_patrol=safe_bool(row.get('æ’å·¡'), default=False, field_name='æ’å·¡', report=report),
                    is_equipment_purchased=safe_bool(row.get('è¨­å‚™å®¢æˆ¶è²·æ–·'), default=False, field_name='è¨­å‚™å®¢æˆ¶è²·æ–·', report=report),
                    is_terminated=safe_bool(row.get('å·²è§£ç´„'), default=False, field_name='å·²è§£ç´„', report=report),
                    needs_same_day_delivery=safe_bool(row.get('éœ€è¦ç•¶å¤©é…é€'), default=False, field_name='éœ€è¦ç•¶å¤©é…é€', report=report),
                    
                    # Business info
                    closed_days=safe_str(row.get('å…¬ä¼‘æ—¥', ''), field_name='å…¬ä¼‘æ—¥', report=report),
                    
                    # Equipment - default to False
                    regulator_model=safe_str(row.get('åˆ‡æ›¿å™¨å‹è™Ÿ', ''), field_name='åˆ‡æ›¿å™¨å‹è™Ÿ', report=report),
                    has_flow_meter=safe_bool(row.get('æµé‡è¡¨'), default=False, field_name='æµé‡è¡¨', report=report),
                    has_wired_flow_meter=safe_bool(row.get('å¸¶ç·šæµé‡éŒ¶'), default=False, field_name='å¸¶ç·šæµé‡éŒ¶', report=report),
                    has_regulator=safe_bool(row.get('åˆ‡æ›¿å™¨'), default=False, field_name='åˆ‡æ›¿å™¨', report=report),
                    has_pressure_gauge=safe_bool(row.get('æ¥é»å¼å£“åŠ›éŒ¶'), default=False, field_name='æ¥é»å¼å£“åŠ›éŒ¶', report=report),
                    has_pressure_switch=safe_bool(row.get('å£“å·®é–‹é—œ'), default=False, field_name='å£“å·®é–‹é—œ', report=report),
                    has_micro_switch=safe_bool(row.get('å¾®å‹•é–‹é—œ'), default=False, field_name='å¾®å‹•é–‹é—œ', report=report),
                    has_smart_scale=safe_bool(row.get('æ™ºæ…§ç§¤'), default=False, field_name='æ™ºæ…§ç§¤', report=report),
                    
                    # Customer type
                    customer_type=safe_str(row.get('é¡å‹', ''), field_name='é¡å‹', report=report)
                )
                
                # Handle delivery time slots
                time_found = False
                for hour in range(8, 20):
                    time_slot = f"{hour}~{hour+1}"
                    if time_slot in df.columns and not pd.isna(row.get(time_slot)):
                        customer.delivery_time_start = f"{hour:02d}:00"
                        customer.delivery_time_end = f"{hour+1:02d}:00"
                        time_found = True
                        break
                
                if not time_found:
                    # Default delivery time 8:00-17:00
                    customer.delivery_time_start = "08:00"
                    customer.delivery_time_end = "17:00"
                
                # Validate critical data
                if not customer.address:
                    report.add_warning(idx, customer_code, 'Missing address')
                
                if customer.avg_daily_usage == 0 and any([
                    customer.cylinders_50kg, customer.cylinders_20kg, 
                    customer.cylinders_16kg, customer.cylinders_10kg, customer.cylinders_4kg
                ]):
                    report.add_warning(idx, customer_code, 'Has cylinders but no daily usage data')
                
                session.add(customer)
                report.successful_imports += 1
                
                # Commit every 100 records
                if report.successful_imports % 100 == 0:
                    await session.commit()
                    print(f"âœ… Imported {report.successful_imports} customers...")
                    
            except Exception as e:
                report.failed_imports += 1
                report.add_error(idx, customer_code if 'customer_code' in locals() else 'Unknown', str(e))
                print(f"âŒ Error importing row {idx}: {e}")
                continue
        
        # Final commit
        await session.commit()
        
    # Generate and save report
    final_report = report.generate_report()
    
    # Print summary
    print("\n" + "="*60)
    print("ğŸ“Š IMPORT SUMMARY")
    print("="*60)
    print(f"âœ… Successfully imported: {report.successful_imports}")
    print(f"â­ï¸  Skipped (existing): {report.skipped_existing}")
    print(f"âŒ Failed: {report.failed_imports}")
    print(f"ğŸ“ˆ Success rate: {final_report['summary']['success_rate']}")
    
    print("\nğŸ” DATA QUALITY SUMMARY")
    print(f"Total NaN replacements: {final_report['data_quality']['total_nan_replacements']}")
    print("\nTop 10 fields with NaN replacements:")
    for field, count in final_report['data_quality']['fields_with_most_nan'][:10]:
        print(f"  - {field}: {count} replacements")
    
    if report.warnings:
        print(f"\nâš ï¸  Total warnings: {len(report.warnings)}")
        print("Sample warnings:")
        for warning in report.warnings[:5]:
            print(f"  - Row {warning['row']} ({warning['customer_code']}): {warning['warning']}")
    
    # Save detailed report to file
    report_path = Path(__file__).parent / f"import_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“„ Detailed report saved to: {report_path}")


if __name__ == "__main__":
    asyncio.run(import_customers())